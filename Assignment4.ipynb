{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\PriyaMehta\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\PriyaMehta\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\PriyaMehta\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\PriyaMehta\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\PriyaMehta\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\PriyaMehta\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import punkt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace(r'\\d+','')\n",
    "    text = re.sub(r'\\d+','', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Precision, Recall, F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrecision(val_tup):\n",
    "    tn, fp, fn, tp  = val_tup\n",
    "    return tp/(tp+fp)\n",
    "\n",
    "def getRecall(val_tup):\n",
    "    tn, fp, fn, tp  = val_tup\n",
    "    return tp/(tp+fn)\n",
    "\n",
    "def getAccuracy(val_tup):\n",
    "    tn, fp, fn, tp  = val_tup\n",
    "    return (tp+tn)/(tp+tn+fp+fn)\n",
    "\n",
    "def getF1Score(val_tup):\n",
    "    pre = getPrecision(val_tup)\n",
    "    rec = getRecall(val_tup)\n",
    "    return 2*(pre*rec)/(pre+rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorization(data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform(data)\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist()\n",
    "    retX = pd.DataFrame(denselist, columns=feature_names)\n",
    "    return retX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r'SMSSpamCollection', 'r')\n",
    "df = pd.read_csv(r'SMSSpamCollection',sep=\"\\t\",header=None)\n",
    "myDict = {'ham' : 0, 'spam' : 1}\n",
    "for x in range(df[0].size):\n",
    "    df[0][x] = myDict[df[0][x]]\n",
    "    df[1][x] = preprocess(df[1][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = vectorization(df[1])\n",
    "cat = df[0]\n",
    "cat = cat.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, train_cat, test_cat = train_test_split(text, cat, random_state = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRmodel = LogisticRegression()\n",
    "LRmodel.fit(train_text, train_cat)\n",
    "\n",
    "LRoutput = LRmodel.predict(test_text)\n",
    "\n",
    "LRmatrix = confusion_matrix(LRoutput, test_cat.values).ravel()\n",
    "\n",
    "LRprecision = getPrecision(LRmatrix)\n",
    "LRrecall = getRecall(LRmatrix)\n",
    "LRaccuracy = getAccuracy(LRmatrix)\n",
    "LRf1score = getF1Score(LRmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM = svm.SVC()\n",
    "SVM.fit(train_text, train_cat)\n",
    "\n",
    "SVMoutput = SVM.predict(test_text)\n",
    "\n",
    "SVMmatrix = confusion_matrix(SVMoutput, test_cat.values).ravel()\n",
    "\n",
    "SVMprecision = getPrecision(SVMmatrix)\n",
    "SVMrecall = getRecall(SVMmatrix)\n",
    "SVMaccuracy = getAccuracy(SVMmatrix)\n",
    "SVMf1score = getF1Score(SVMmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "KNN.fit(train_text, train_cat)\n",
    "\n",
    "KNNoutput = KNN.predict(test_text)\n",
    "\n",
    "KNNmatrix = confusion_matrix(KNNoutput, test_cat.values).ravel()\n",
    "\n",
    "KNNprecision = getPrecision(KNNmatrix)\n",
    "KNNrecall = getRecall(KNNmatrix)\n",
    "KNNaccuracy = getAccuracy(KNNmatrix)\n",
    "KNNf1score = getF1Score(KNNmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PriyaMehta\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\PriyaMehta\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "4179/4179 [==============================] - 4s 895us/step - loss: 0.3392 - accuracy: 0.8954\n",
      "Epoch 2/20\n",
      "4179/4179 [==============================] - 3s 625us/step - loss: 0.0627 - accuracy: 0.9840\n",
      "Epoch 3/20\n",
      "4179/4179 [==============================] - 3s 627us/step - loss: 0.0238 - accuracy: 0.9935\n",
      "Epoch 4/20\n",
      "4179/4179 [==============================] - 3s 652us/step - loss: 0.0110 - accuracy: 0.9978\n",
      "Epoch 5/20\n",
      "4179/4179 [==============================] - 3s 624us/step - loss: 0.0062 - accuracy: 0.9993\n",
      "Epoch 6/20\n",
      "4179/4179 [==============================] - 3s 619us/step - loss: 0.0035 - accuracy: 0.9998\n",
      "Epoch 7/20\n",
      "4179/4179 [==============================] - 3s 641us/step - loss: 0.0020 - accuracy: 0.9998\n",
      "Epoch 8/20\n",
      "4179/4179 [==============================] - 3s 616us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "4179/4179 [==============================] - 3s 618us/step - loss: 8.1458e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "4179/4179 [==============================] - 2s 581us/step - loss: 5.6209e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "4179/4179 [==============================] - 2s 585us/step - loss: 4.0161e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "4179/4179 [==============================] - 3s 633us/step - loss: 2.9239e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "4179/4179 [==============================] - 2s 584us/step - loss: 2.1756e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "4179/4179 [==============================] - 2s 582us/step - loss: 1.6169e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "4179/4179 [==============================] - 2s 589us/step - loss: 1.2158e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "4179/4179 [==============================] - 2s 583us/step - loss: 9.2360e-05 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "4179/4179 [==============================] - 2s 572us/step - loss: 7.1777e-05 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "4179/4179 [==============================] - 2s 532us/step - loss: 5.4363e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "4179/4179 [==============================] - 2s 535us/step - loss: 4.2332e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "4179/4179 [==============================] - 3s 603us/step - loss: 3.2711e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "NeuralNetwork = Sequential()\n",
    "NeuralNetwork.add(Dense(12, input_dim=7822, activation='relu'))\n",
    "NeuralNetwork.add(Dense(8, activation='relu'))\n",
    "NeuralNetwork.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "NeuralNetwork.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "NeuralNetwork.fit(train_text, train_cat, epochs=20, batch_size=10)\n",
    "\n",
    "NNoutput = NeuralNetwork.predict_classes(test_text)\n",
    "\n",
    "NNmatrix = confusion_matrix(NNoutput, test_cat.values).ravel()\n",
    "\n",
    "NNprecision = getPrecision(NNmatrix)\n",
    "NNrecall = getRecall(NNmatrix)\n",
    "NNaccuracy = getAccuracy(NNmatrix)\n",
    "NNf1score = getF1Score(NNmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type                  Precision           Recall                Accuracy             F1 Score\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Logistic Regression   0.7631578947368421   0.9797297297297297   0.9655419956927495   0.8579881656804733\n",
      "SVM                   0.8578947368421053   0.9878787878787879   0.9791816223977028   0.9183098591549295\n",
      "KNN                   0.35789473684210527   1.0                 0.9124192390524049   0.5271317829457365\n",
      "Neural Network        0.9263157894736842   0.9617486338797814   0.9849246231155779   0.9436997319034852\n"
     ]
    }
   ],
   "source": [
    "print('Type                  Precision           Recall                Accuracy             F1 Score')\n",
    "print('-------------------------------------------------------------------------------------------------------')\n",
    "print('Logistic Regression',LRprecision,LRrecall,LRaccuracy,LRf1score, sep='   ')\n",
    "print('SVM                ',SVMprecision,SVMrecall,SVMaccuracy,SVMf1score, sep='   ')\n",
    "print('KNN                ',KNNprecision,KNNrecall,'           ',KNNaccuracy,KNNf1score, sep='   ')\n",
    "print('Neural Network     ',NNprecision,NNrecall,NNaccuracy,NNf1score, sep='   ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

# Natural Language Processing

Here I have uploaded my Information Retrieval assignments in form of Jupyter Notebooks. It explores basic Natural Language Processing and various useful Python libraries for the same. It's easy to follow and any beginner can go through it to get started!

## Assignment 1: 
Aim is to perform necessary Data Preprocessing and observe changes while applying various techniques. It starts by parsing HTML file to obtain data and ends by comparing Stemming vs Lemmatization.\
Libaries used are BeautifulSoup, NLTK, Pandas, Regular Expression

## Assignment 2: 
Aim is to get familiar with TF-IDF Vectorization. Compare manually written functions to that provided in sklearn.\
Libaries used are xml(to parse XML input data), os, numpy, NLTK, Pandas, sklearn

## Assignment 3: 
Aim is to convert text to vectors and then computing cosine similarity to find relevant documents based on the query. \
Note: For processing huge number of documents, powerful machine is needed. Here I processed only a few so results are not that accurate.

## Assignment 4:
Experimenting with techniques like SVM, KNN, Logistic Regression, Neural Networks and comparing using standard measures like Precision, Recall, Accuracy and F1 Score. 


Guidance: Prof. Sandip Modha

Note: I haven't uploaded the datasets because of it's large size. But if needed to understand the code, feel free to ping me.
